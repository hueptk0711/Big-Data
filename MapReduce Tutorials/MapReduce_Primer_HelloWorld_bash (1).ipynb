{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/groda/big_data/blob/master/MapReduce_Primer_HelloWorld_bash.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","source":["<a href=\"https://github.com/groda/big_data\"><div><img src=\"https://github.com/groda/big_data/blob/master/logo_bdb.png?raw=true\" align=right width=\"90\"></div></a>\n","\n","# MapReduce: A Primer with <code>Hello World!</code> in bash\n","<br>\n","<br>\n","\n","This tutorial serves as a companion to [MapReduce_Primer_HelloWorld.ipynb](https://github.com/groda/big_data/blob/master/MapReduce_Primer_HelloWorld.ipynb), with the implementation carried out in the Bash scripting language requiring only a few lines of code.\n","\n","For this tutorial, we are going to download the core Hadoop distribution and run Hadoop in _local standalone mode_:\n","\n","> ❝ _By default, Hadoop is configured to run in a non-distributed mode, as a single Java process._ ❞\n","\n","(see [https://hadoop.apache.org/docs/stable/.../Standalone_Operation](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#Standalone_Operation))\n","\n","We are going to run a MapReduce job using MapReduce's [streaming application](https://hadoop.apache.org/docs/stable/hadoop-streaming/HadoopStreaming.html#Hadoop_Streaming). This is not to be confused with real-time streaming:\n","\n","> ❝ _Hadoop streaming is a utility that comes with the Hadoop distribution. The utility allows you to create and run Map/Reduce jobs with any executable or script as the mapper and/or the reducer._ ❞\n","\n","MapReduce streaming defaults to using [`IdentityMapper`](https://hadoop.apache.org/docs/stable/api/index.html) and [`IdentityReducer`](https://hadoop.apache.org/docs/stable/api/index.html), thus eliminating the need for explicit specification of a mapper or reducer.\n","\n","Both input and output are standard files since Hadoop's default filesystem is the regular file system, as specified by the `fs.defaultFS` property in [core-default.xml](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/core-default.xml)).\n"],"metadata":{"id":"YCd6jCrqlSXw"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6j5zZwJMkc6C","outputId":"20053a2d-3b7e-4397-e199-3fb8720ffc92","executionInfo":{"status":"ok","timestamp":1713894081099,"user_tz":-420,"elapsed":46615,"user":{"displayName":"Huệ Phạm Thị Kim","userId":"13314167880737377603"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["output20240423T1741:\n","total 4\n","-rw-r--r-- 1 root root 16 Apr 23 17:41 part-00000\n","-rw-r--r-- 1 root root  0 Apr 23 17:41 _SUCCESS\n","0\tHello, World!\n"]},{"output_type":"stream","name":"stderr","text":["2024-04-23 17:41:18,727 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n","2024-04-23 17:41:19,148 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n","2024-04-23 17:41:19,149 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n","2024-04-23 17:41:19,190 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n","2024-04-23 17:41:19,737 INFO mapred.FileInputFormat: Total input files to process : 1\n","2024-04-23 17:41:19,797 INFO mapreduce.JobSubmitter: number of splits:1\n","2024-04-23 17:41:20,443 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1772419582_0001\n","2024-04-23 17:41:20,443 INFO mapreduce.JobSubmitter: Executing with tokens: []\n","2024-04-23 17:41:20,758 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n","2024-04-23 17:41:20,761 INFO mapreduce.Job: Running job: job_local1772419582_0001\n","2024-04-23 17:41:20,775 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n","2024-04-23 17:41:20,779 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n","2024-04-23 17:41:20,794 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-04-23 17:41:20,794 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-04-23 17:41:20,867 INFO mapred.LocalJobRunner: Waiting for map tasks\n","2024-04-23 17:41:20,875 INFO mapred.LocalJobRunner: Starting task: attempt_local1772419582_0001_m_000000_0\n","2024-04-23 17:41:20,962 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-04-23 17:41:20,965 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-04-23 17:41:21,017 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-04-23 17:41:21,034 INFO mapred.MapTask: Processing split: file:/content/hello.txt:0+14\n","2024-04-23 17:41:21,053 INFO mapred.MapTask: numReduceTasks: 1\n","2024-04-23 17:41:21,247 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-04-23 17:41:21,247 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-04-23 17:41:21,247 INFO mapred.MapTask: soft limit at 83886080\n","2024-04-23 17:41:21,247 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-04-23 17:41:21,247 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-04-23 17:41:21,252 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-04-23 17:41:21,260 INFO mapred.LocalJobRunner: \n","2024-04-23 17:41:21,260 INFO mapred.MapTask: Starting flush of map output\n","2024-04-23 17:41:21,260 INFO mapred.MapTask: Spilling map output\n","2024-04-23 17:41:21,261 INFO mapred.MapTask: bufstart = 0; bufend = 22; bufvoid = 104857600\n","2024-04-23 17:41:21,261 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n","2024-04-23 17:41:21,272 INFO mapred.MapTask: Finished spill 0\n","2024-04-23 17:41:21,296 INFO mapred.Task: Task:attempt_local1772419582_0001_m_000000_0 is done. And is in the process of committing\n","2024-04-23 17:41:21,301 INFO mapred.LocalJobRunner: file:/content/hello.txt:0+14\n","2024-04-23 17:41:21,301 INFO mapred.Task: Task 'attempt_local1772419582_0001_m_000000_0' done.\n","2024-04-23 17:41:21,311 INFO mapred.Task: Final Counters for attempt_local1772419582_0001_m_000000_0: Counters: 17\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=141410\n","\t\tFILE: Number of bytes written=779423\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=1\n","\t\tMap output records=1\n","\t\tMap output bytes=22\n","\t\tMap output materialized bytes=30\n","\t\tInput split bytes=75\n","\t\tCombine input records=0\n","\t\tSpilled Records=1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=341835776\n","\tFile Input Format Counters \n","\t\tBytes Read=14\n","2024-04-23 17:41:21,311 INFO mapred.LocalJobRunner: Finishing task: attempt_local1772419582_0001_m_000000_0\n","2024-04-23 17:41:21,312 INFO mapred.LocalJobRunner: map task executor complete.\n","2024-04-23 17:41:21,318 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n","2024-04-23 17:41:21,319 INFO mapred.LocalJobRunner: Starting task: attempt_local1772419582_0001_r_000000_0\n","2024-04-23 17:41:21,338 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-04-23 17:41:21,338 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-04-23 17:41:21,339 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-04-23 17:41:21,348 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6763c4e7\n","2024-04-23 17:41:21,351 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n","2024-04-23 17:41:21,387 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n","2024-04-23 17:41:21,393 INFO reduce.EventFetcher: attempt_local1772419582_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n","2024-04-23 17:41:21,442 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1772419582_0001_m_000000_0 decomp: 26 len: 30 to MEMORY\n","2024-04-23 17:41:21,447 INFO reduce.InMemoryMapOutput: Read 26 bytes from map-output for attempt_local1772419582_0001_m_000000_0\n","2024-04-23 17:41:21,451 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 26, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->26\n","2024-04-23 17:41:21,452 WARN io.ReadaheadPool: Failed readahead on ifile\n","EBADF: Bad file descriptor\n","\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n","\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:426)\n","\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:296)\n","\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:220)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","2024-04-23 17:41:21,458 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n","2024-04-23 17:41:21,460 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-04-23 17:41:21,460 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n","2024-04-23 17:41:21,469 INFO mapred.Merger: Merging 1 sorted segments\n","2024-04-23 17:41:21,470 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 16 bytes\n","2024-04-23 17:41:21,472 INFO reduce.MergeManagerImpl: Merged 1 segments, 26 bytes to disk to satisfy reduce memory limit\n","2024-04-23 17:41:21,473 INFO reduce.MergeManagerImpl: Merging 1 files, 30 bytes from disk\n","2024-04-23 17:41:21,474 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n","2024-04-23 17:41:21,474 INFO mapred.Merger: Merging 1 sorted segments\n","2024-04-23 17:41:21,475 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 16 bytes\n","2024-04-23 17:41:21,476 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-04-23 17:41:21,488 INFO mapred.Task: Task:attempt_local1772419582_0001_r_000000_0 is done. And is in the process of committing\n","2024-04-23 17:41:21,492 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-04-23 17:41:21,494 INFO mapred.Task: Task attempt_local1772419582_0001_r_000000_0 is allowed to commit now\n","2024-04-23 17:41:21,499 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1772419582_0001_r_000000_0' to file:/content/output20240423T1741\n","2024-04-23 17:41:21,505 INFO mapred.LocalJobRunner: reduce > reduce\n","2024-04-23 17:41:21,505 INFO mapred.Task: Task 'attempt_local1772419582_0001_r_000000_0' done.\n","2024-04-23 17:41:21,506 INFO mapred.Task: Final Counters for attempt_local1772419582_0001_r_000000_0: Counters: 24\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=141502\n","\t\tFILE: Number of bytes written=779481\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tReduce input groups=1\n","\t\tReduce shuffle bytes=30\n","\t\tReduce input records=1\n","\t\tReduce output records=1\n","\t\tSpilled Records=1\n","\t\tShuffled Maps =1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=1\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=341835776\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","\tFile Output Format Counters \n","\t\tBytes Written=28\n","2024-04-23 17:41:21,506 INFO mapred.LocalJobRunner: Finishing task: attempt_local1772419582_0001_r_000000_0\n","2024-04-23 17:41:21,506 INFO mapred.LocalJobRunner: reduce task executor complete.\n","2024-04-23 17:41:21,773 INFO mapreduce.Job: Job job_local1772419582_0001 running in uber mode : false\n","2024-04-23 17:41:21,775 INFO mapreduce.Job:  map 100% reduce 100%\n","2024-04-23 17:41:21,776 INFO mapreduce.Job: Job job_local1772419582_0001 completed successfully\n","2024-04-23 17:41:21,787 INFO mapreduce.Job: Counters: 30\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=282912\n","\t\tFILE: Number of bytes written=1558904\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=1\n","\t\tMap output records=1\n","\t\tMap output bytes=22\n","\t\tMap output materialized bytes=30\n","\t\tInput split bytes=75\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tReduce input groups=1\n","\t\tReduce shuffle bytes=30\n","\t\tReduce input records=1\n","\t\tReduce output records=1\n","\t\tSpilled Records=2\n","\t\tShuffled Maps =1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=1\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=683671552\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","\tFile Input Format Counters \n","\t\tBytes Read=14\n","\tFile Output Format Counters \n","\t\tBytes Written=28\n","2024-04-23 17:41:21,787 INFO streaming.StreamJob: Output directory: output20240423T1741\n"]}],"source":["%%bash\n","#set -x\n","HADOOP_URL=\"https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz\"\n","wget --quiet --no-clobber $HADOOP_URL >/dev/null\n","[ ! -d $(basename $HADOOP_URL .tar.gz) ] && tar -xzf $(basename $HADOOP_URL)\n","HADOOP_HOME=$(pwd)'/'$(basename $HADOOP_URL .tar.gz)'/bin'\n","PATH=$HADOOP_HOME:$PATH\n","which java >/dev/null|| apt install -y openjdk-19-jre-headless\n","export JAVA_HOME=$(realpath $(which java) | sed 's/\\/bin\\/java$//')\n","echo -e \"Hello, World!\">hello.txt\n","output_dir=\"output\"$(date +\"%Y%m%dT%H%M\")\n","sleep 10\n","mapred streaming -input hello.txt -output $output_dir\n","ls -lR output*\n","cat $output_dir/part-00000"]}]}